# ğŸ“˜ E-Learning 5 - Exercise 2 - Question B: So SÃ¡nh vá»›i Sklearn

## ğŸ¯ Má»¥c TiÃªu BÃ i Táº­p

BÃ i táº­p yÃªu cáº§u **so sÃ¡nh káº¿t quáº£** giá»¯a **mÃ´ hÃ¬nh Logistic Regression tá»± xÃ¢y dá»±ng** (Question A) vá»›i **mÃ´ hÃ¬nh tá»« thÆ° viá»‡n sklearn** Ä‘á»ƒ kiá»ƒm chá»©ng tÃ­nh Ä‘Ãºng Ä‘áº¯n cá»§a implementation.

### ğŸ“Š Äá» BÃ i

**YÃªu cáº§u:**

-   Sá»­ dá»¥ng **cÃ¹ng dataset** nhÆ° Question A
-   Huáº¥n luyá»‡n mÃ´ hÃ¬nh báº±ng **sklearn.linear_model.LogisticRegression**
-   **So sÃ¡nh** káº¿t quáº£ giá»¯a 2 mÃ´ hÃ¬nh:
    -   Tham sá»‘ há»c Ä‘Æ°á»£c (m/coef, b/intercept)
    -   XÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho 2.8 giá» há»c
    -   Káº¿t luáº­n Ä‘áº­u/rá»›t
-   **Visualization:** Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh trá»±c quan

---

## ğŸ’» PhÃ¢n TÃ­ch Source Code Chi Tiáº¿t

### 1ï¸âƒ£ Import Libraries

```python
import sys
import os
# ThÃªm thÆ° má»¥c cha vÃ o path Ä‘á»ƒ import module
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from logistic_regression_utils import (
    DATASET, get_prediction, train_logistic_regression
)
from sklearn.linear_model import LogisticRegression
import numpy as np
import matplotlib.pyplot as plt
```

**Giáº£i thÃ­ch:**

#### **Import module tá»± xÃ¢y dá»±ng**

```python
from logistic_regression_utils import (
    DATASET, get_prediction, train_logistic_regression
)
```

-   Import cÃ¡c hÃ m tá»« Question A Ä‘á»ƒ sá»­ dá»¥ng láº¡i
-   **TÃ¡i sá»­ dá»¥ng code:** KhÃ´ng viáº¿t láº¡i logic training

#### **Import sklearn**

```python
from sklearn.linear_model import LogisticRegression
```

-   **sklearn:** ThÆ° viá»‡n Machine Learning phá»• biáº¿n nháº¥t Python
-   **LogisticRegression:** Class implement Logistic Regression chuáº©n, tá»‘i Æ°u
-   **Äáº·c Ä‘iá»ƒm:**
    -   Highly optimized (C/C++ backend)
    -   Nhiá»u thuáº­t toÃ¡n tá»‘i Æ°u: LBFGS, SAG, SAGA, ...
    -   ÄÆ°á»£c test ká»¹ lÆ°á»¡ng, Ä‘Ã¡ng tin cáº­y

#### **Import numpy vÃ  matplotlib**

```python
import numpy as np
import matplotlib.pyplot as plt
```

-   **numpy:** Sklearn yÃªu cáº§u input dáº¡ng numpy array
-   **matplotlib:** Äá»ƒ váº½ biá»ƒu Ä‘á»“ so sÃ¡nh

---

### 2ï¸âƒ£ PHáº¦N A: MÃ´ HÃ¬nh Tá»± XÃ¢y Dá»±ng

```python
# ========== PHáº¦N A: MÃ” HÃŒNH Tá»° XÃ‚Y Dá»°NG ==========

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i n = 10 iterations
m, b, costs = train_logistic_regression(
    dataset=DATASET,
    m_init=1.0,
    b_init=-1.0,
    iterations=10,
    learning_rate=1.0
)
# Dá»± Ä‘oÃ¡n cho sinh viÃªn há»c 2.8 giá»
hours_input = 2.8
predicted_score_manual = get_prediction(m, b, hours_input)
```

**Giáº£i thÃ­ch:**

#### **Training**

-   Sá»­ dá»¥ng **láº¡i code tá»« Question A**
-   Cháº¡y Ä‘Ãºng 10 iterations nhÆ° yÃªu cáº§u Ä‘á» bÃ i
-   Tham sá»‘ khá»Ÿi táº¡o: m=1.0, b=-1.0, learning_rate=1.0

#### **Prediction**

-   Dá»± Ä‘oÃ¡n cho 2.8 giá»
-   LÆ°u vÃ o `predicted_score_manual` Ä‘á»ƒ so sÃ¡nh sau

**Táº¡i sao gá»i lÃ  "manual"?**

-   Äá»ƒ phÃ¢n biá»‡t vá»›i sklearn (automated/optimized)
-   "Manual" = tá»± code tá»« Ä‘áº§u, tá»«ng bÆ°á»›c

---

### 3ï¸âƒ£ In Káº¿t Quáº£ MÃ´ HÃ¬nh Tá»± XÃ¢y Dá»±ng

```python
print("\n" + "="*60)
print("BÃ€I 2 - QUESTION B: SO SÃNH MÃ” HÃŒNH Tá»° XÃ‚Y Dá»°NG Vá»šI SKLEARN")
print("="*60)

print("\n" + "-"*60)
print("PHáº¦N A: Káº¾T QUáº¢ MÃ” HÃŒNH Tá»° XÃ‚Y Dá»°NG")
print("-"*60)
print(f"Tham sá»‘ há»c Ä‘Æ°á»£c:")
print(f"  - Há»‡ sá»‘ gÃ³c (m): {m:.6f}")
print(f"  - Há»‡ sá»‘ cháº·n (b): {b:.6f}")
print(f"\nDá»± Ä‘oÃ¡n cho sinh viÃªn há»c {hours_input} giá»:")
print(f"  - XÃ¡c suáº¥t Ä‘áº­u: {predicted_score_manual:.6f} ({predicted_score_manual*100:.2f}%)")
if predicted_score_manual >= 0.5:
    print(f"  - Káº¿t luáº­n: Äáº¬U")
else:
    print(f"  - Káº¿t luáº­n: Rá»šT")
```

**Giáº£i thÃ­ch:**

#### **Cáº¥u trÃºc output**

-   **Header lá»›n (=):** TiÃªu Ä‘á» bÃ i toÃ¡n
-   **Header nhá» (-):** TiÃªu Ä‘á» tá»«ng pháº§n

#### **In tham sá»‘**

```python
print(f"  - Há»‡ sá»‘ gÃ³c (m): {m:.6f}")
print(f"  - Há»‡ sá»‘ cháº·n (b): {b:.6f}")
```

-   `.6f`: 6 chá»¯ sá»‘ tháº­p phÃ¢n (Ä‘á»™ chÃ­nh xÃ¡c cao)
-   Thá»¥t Ä‘áº§u dÃ²ng ` -` Ä‘á»ƒ dá»… Ä‘á»c

#### **In káº¿t quáº£ dá»± Ä‘oÃ¡n**

```python
print(f"  - XÃ¡c suáº¥t Ä‘áº­u: {predicted_score_manual:.6f} ({predicted_score_manual*100:.2f}%)")
```

-   In cáº£ dáº¡ng tháº­p phÃ¢n vÃ  pháº§n trÄƒm
-   VÃ­ dá»¥: `0.785432 (78.54%)`

#### **Káº¿t luáº­n**

```python
if predicted_score_manual >= 0.5:
    print(f"  - Káº¿t luáº­n: Äáº¬U")
else:
    print(f"  - Káº¿t luáº­n: Rá»šT")
```

-   Logic Ä‘Æ¡n giáº£n: â‰¥ 0.5 â†’ Äáº¬U

---

### 4ï¸âƒ£ PHáº¦N B: MÃ´ HÃ¬nh Sklearn

#### **4.1. Chuáº©n Bá»‹ Dá»¯ Liá»‡u**

```python
# Chuáº©n bá»‹ dá»¯ liá»‡u cho sklearn
X = np.array([[row[0]] for row in DATASET])  # Features (Hours)
y_train = np.array([row[1] for row in DATASET])  # Labels (Pass)
```

**Giáº£i thÃ­ch:**

##### **Features (X)**

```python
X = np.array([[row[0]] for row in DATASET])
```

**PhÃ¢n tÃ­ch:**

-   `row[0]`: Láº¥y cá»™t Ä‘áº§u (Hours)
-   `[[row[0]]]`: **ChÃº Ã½ 2 cáº·p ngoáº·c vuÃ´ng!**
    -   Ngoáº·c trong `[row[0]]`: Táº¡o list 1 pháº§n tá»­
    -   Ngoáº·c ngoÃ i `[...]`: List comprehension

**Táº¡i sao cáº§n 2 cáº·p ngoáº·c?**

Sklearn yÃªu cáº§u X pháº£i lÃ  **ma tráº­n 2D** (n_samples Ã— n_features):

-   `n_samples`: Sá»‘ máº«u (8 Ä‘iá»ƒm)
-   `n_features`: Sá»‘ features (1 feature = hours)

**Káº¿t quáº£:**

```python
X = [[0.5],
     [1.0],
     [1.5],
     [2.0],
     [2.5],
     [3.0],
     [3.5],
     [4.0]]
# Shape: (8, 1) - 8 hÃ ng, 1 cá»™t
```

**Náº¿u chá»‰ dÃ¹ng 1 cáº·p ngoáº·c:**

```python
X = np.array([row[0] for row in DATASET])
# Káº¿t quáº£: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]
# Shape: (8,) - 1D array â†’ sklearn bÃ¡o lá»—i!
```

##### **Labels (y_train)**

```python
y_train = np.array([row[1] for row in DATASET])
```

**PhÃ¢n tÃ­ch:**

-   `row[1]`: Láº¥y cá»™t thá»© 2 (Pass)
-   Chá»‰ cáº§n 1D array: `[0, 0, 0, 0, 1, 1, 1, 1]`
-   Shape: (8,) - 8 pháº§n tá»­

**LÆ°u Ã½ naming:**

-   Äáº·t tÃªn `y_train` thay vÃ¬ `y` Ä‘á»ƒ trÃ¡nh nháº§m láº«n vá»›i biáº¿n `y` tá»« pháº§n A

---

#### **4.2. Táº¡o vÃ  Huáº¥n Luyá»‡n MÃ´ HÃ¬nh**

```python
# Táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression
model = LogisticRegression(max_iter=10, solver='lbfgs', random_state=42)
model.fit(X, y_train)
```

**Giáº£i thÃ­ch:**

##### **Táº¡o model**

```python
model = LogisticRegression(max_iter=10, solver='lbfgs', random_state=42)
```

**CÃ¡c tham sá»‘:**

1. **`max_iter=10`**

    - **Maximum iterations:** Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a
    - Äáº·t = 10 Ä‘á»ƒ **cÃ´ng báº±ng** vá»›i mÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng
    - Máº·c Ä‘á»‹nh sklearn = 100
    - **LÆ°u Ã½:** Sklearn cÃ³ thá»ƒ há»™i tá»¥ sá»›m hÆ¡n 10 iterations náº¿u Ä‘áº¡t tolerance

2. **`solver='lbfgs'`**

    - **Thuáº­t toÃ¡n tá»‘i Æ°u:** Limited-memory BFGS
    - **LBFGS (Limited-memory Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno):**
        - Thuáº­t toÃ¡n quasi-Newton
        - Hiá»‡u quáº£ hÆ¡n Gradient Descent thÃ´ng thÆ°á»ng
        - Sá»­ dá»¥ng approximation cá»§a ma tráº­n Hessian
        - Tá»‘t cho dataset nhá»/trung bÃ¬nh

    **CÃ¡c solver khÃ¡c:**

    - `'liblinear'`: Tá»‘t cho dataset nhá»
    - `'saga'`: Tá»‘t cho dataset lá»›n
    - `'sag'`: Stochastic Average Gradient
    - `'newton-cg'`: Newton-Conjugate-Gradient

3. **`random_state=42`**
    - **Seed cho random number generator**
    - Äáº£m báº£o **káº¿t quáº£ reproducible** (cháº¡y láº¡i ra cÃ¹ng káº¿t quáº£)
    - 42 lÃ  sá»‘ phá»• biáº¿n (The Hitchhiker's Guide to the Galaxy reference ğŸ˜Š)
    - Quan trá»ng cho debugging vÃ  so sÃ¡nh

**Táº¡i sao sklearn cáº§n random_state?**

-   Má»™t sá»‘ solver khá»Ÿi táº¡o tham sá»‘ ngáº«u nhiÃªn
-   Shuffling data khi dÃ¹ng batch methods
-   Äáº£m báº£o reproducibility cho scientific research

##### **Fit model**

```python
model.fit(X, y_train)
```

**Giáº£i thÃ­ch:**

-   **`fit(X, y)`:** HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh
-   **Input:**
    -   `X`: Features (8Ã—1 matrix)
    -   `y_train`: Labels (8 elements)
-   **Process:**
    -   Cháº¡y thuáº­t toÃ¡n LBFGS
    -   Tá»‘i Æ°u hÃ³a tham sá»‘ (coef, intercept)
    -   Tá»‘i Ä‘a 10 iterations
-   **Output:**
    -   `model` Ä‘Æ°á»£c cáº­p nháº­t (in-place)
    -   Tham sá»‘ Ä‘Æ°á»£c lÆ°u trong `model.coef_` vÃ  `model.intercept_`

**LÆ°u Ã½:**

-   Sklearn tá»± Ä‘á»™ng normalize/standardize náº¿u cáº§n
-   Tá»± Ä‘á»™ng handle convergence
-   Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh learning rate (adaptive)

---

#### **4.3. Dá»± ÄoÃ¡n vá»›i Sklearn**

```python
# Dá»± Ä‘oÃ¡n vá»›i sklearn
X_test = np.array([[hours_input]])
predicted_proba_sklearn = model.predict_proba(X_test)[0][1]  # XÃ¡c suáº¥t cho class 1 (Pass)
predicted_class_sklearn = model.predict(X_test)[0]
```

**Giáº£i thÃ­ch:**

##### **Chuáº©n bá»‹ test data**

```python
X_test = np.array([[hours_input]])
```

-   `hours_input = 2.8`
-   `[[2.8]]`: Ma tráº­n 2D (1Ã—1) - 1 sample, 1 feature
-   **Pháº£i cÃ¹ng format** vá»›i X training (2D)

##### **Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t**

```python
predicted_proba_sklearn = model.predict_proba(X_test)[0][1]
```

**PhÃ¢n tÃ­ch:**

1. **`model.predict_proba(X_test)`:**

    - Tráº£ vá» **ma tráº­n xÃ¡c suáº¥t** cho táº¥t cáº£ classes
    - Shape: (n_samples, n_classes)
    - Vá»›i X_test shape (1, 1): Output shape (1, 2)
    - **2 classes:** [xÃ¡c suáº¥t class 0, xÃ¡c suáº¥t class 1]

    **VÃ­ dá»¥:**

    ```python
    predict_proba(X_test) = [[0.2146, 0.7854]]
    # Class 0: 21.46%
    # Class 1: 78.54%
    ```

2. **`[0]`:** Láº¥y sample Ä‘áº§u tiÃªn (vÃ¬ chá»‰ cÃ³ 1 sample)

    ```python
    [0.2146, 0.7854]
    ```

3. **`[1]`:** Láº¥y xÃ¡c suáº¥t cá»§a **class 1** (Pass)
    ```python
    0.7854
    ```

**TÃ³m láº¡i:** `[0][1]` = xÃ¡c suáº¥t Pass cá»§a sample Ä‘áº§u tiÃªn

##### **Dá»± Ä‘oÃ¡n class**

```python
predicted_class_sklearn = model.predict(X_test)[0]
```

**PhÃ¢n tÃ­ch:**

1. **`model.predict(X_test)`:**

    - Tráº£ vá» **nhÃ£n dá»± Ä‘oÃ¡n** (0 hoáº·c 1)
    - ÄÃ£ apply threshold 0.5 tá»± Ä‘á»™ng
    - Output: `[1]` (array vá»›i 1 pháº§n tá»­)

2. **`[0]`:** Láº¥y pháº§n tá»­ Ä‘áº§u
    - Káº¿t quáº£: `1` (sá»‘ nguyÃªn)
    - 1 = Äáº­u, 0 = Rá»›t

**So sÃ¡nh predict vs predict_proba:**

| Method          | Output   | Example          |
| --------------- | -------- | ---------------- |
| `predict_proba` | XÃ¡c suáº¥t | `[[0.21, 0.79]]` |
| `predict`       | NhÃ£n     | `[1]`            |

---

#### **4.4. In Káº¿t Quáº£ Sklearn**

```python
print("\n" + "-"*60)
print("PHáº¦N B: Káº¾T QUáº¢ MÃ” HÃŒNH SKLEARN")
print("-"*60)

print(f"Tham sá»‘ há»c Ä‘Æ°á»£c:")
print(f"  - Há»‡ sá»‘ gÃ³c (coef): {model.coef_[0][0]:.6f}")
print(f"  - Há»‡ sá»‘ cháº·n (intercept): {model.intercept_[0]:.6f}")
print(f"\nDá»± Ä‘oÃ¡n cho sinh viÃªn há»c {hours_input} giá»:")
print(f"  - XÃ¡c suáº¥t Ä‘áº­u: {predicted_proba_sklearn:.6f} ({predicted_proba_sklearn*100:.2f}%)")
if predicted_class_sklearn == 1:
    print(f"  - Káº¿t luáº­n: Äáº¬U")
else:
    print(f"  - Káº¿t luáº­n: Rá»šT")
```

**Giáº£i thÃ­ch:**

##### **Truy cáº­p tham sá»‘ sklearn**

**Há»‡ sá»‘ gÃ³c:**

```python
model.coef_[0][0]
```

-   **`model.coef_`:** Ma tráº­n há»‡ sá»‘ (n_classes-1, n_features)
    -   Logistic Regression binary: (1, 1)
    -   `[[2.345]]` (1 class, 1 feature)
-   **`[0]`:** Láº¥y hÃ ng Ä‘áº§u: `[2.345]`
-   **`[0]`:** Láº¥y cá»™t Ä‘áº§u: `2.345`

**Há»‡ sá»‘ cháº·n:**

```python
model.intercept_[0]
```

-   **`model.intercept_`:** Array há»‡ sá»‘ cháº·n (n_classes-1,)
    -   `[-4.567]` (1 pháº§n tá»­)
-   **`[0]`:** Láº¥y pháº§n tá»­ Ä‘áº§u: `-4.567`

##### **In káº¿t quáº£**

-   Format giá»‘ng pháº§n A Ä‘á»ƒ dá»… so sÃ¡nh
-   Sá»­ dá»¥ng `.6f` cho Ä‘á»™ chÃ­nh xÃ¡c cao

---

### 5ï¸âƒ£ So SÃ¡nh Káº¿t Quáº£

```python
# ========== SO SÃNH Káº¾T QUáº¢ ==========

print(f"\nHá»‡ sá»‘ gÃ³c (m/coef):")
print(f"  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: {m:.6f}")
print(f"  - Sklearn:              {model.coef_[0][0]:.6f}")
print(f"  - ChÃªnh lá»‡ch:           {abs(m - model.coef_[0][0]):.6f}")

print(f"\nHá»‡ sá»‘ cháº·n (b/intercept):")
print(f"  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: {b:.6f}")
print(f"  - Sklearn:              {model.intercept_[0]:.6f}")
print(f"  - ChÃªnh lá»‡ch:           {abs(b - model.intercept_[0]):.6f}")

print(f"\nXÃ¡c suáº¥t Ä‘áº­u cho {hours_input} giá» há»c:")
print(f"  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: {predicted_score_manual:.6f} ({predicted_score_manual*100:.2f}%)")
print(f"  - Sklearn:              {predicted_proba_sklearn:.6f} ({predicted_proba_sklearn*100:.2f}%)")
print(f"  - ChÃªnh lá»‡ch:           {abs(predicted_score_manual - predicted_proba_sklearn):.6f}")

print(f"\nKáº¿t luáº­n dá»± Ä‘oÃ¡n:")
result_manual = "Äáº¬U" if predicted_score_manual >= 0.5 else "Rá»šT"
result_sklearn = "Äáº¬U" if predicted_class_sklearn == 1 else "Rá»šT"
print(f"  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: {result_manual}")
print(f"  - Sklearn:             {result_sklearn}")
if result_manual == result_sklearn:
    print(f"  - Káº¿t quáº£: GIá»NG NHAU âœ“")
else:
    print(f"  - Káº¿t quáº£: KHÃC NHAU âœ—")
```

**Giáº£i thÃ­ch:**

#### **So sÃ¡nh tá»«ng thÃ nh pháº§n**

##### **1. Há»‡ sá»‘ gÃ³c (m vs coef)**

```python
print(f"  - ChÃªnh lá»‡ch:           {abs(m - model.coef_[0][0]):.6f}")
```

-   TÃ­nh **giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i** cá»§a sá»± chÃªnh lá»‡ch
-   `abs()`: LuÃ´n dÆ°Æ¡ng, dá»… so sÃ¡nh
-   Ká»³ vá»ng: ChÃªnh lá»‡ch nhá» (< 0.1)

##### **2. Há»‡ sá»‘ cháº·n (b vs intercept)**

```python
print(f"  - ChÃªnh lá»‡ch:           {abs(b - model.intercept_[0]):.6f}")
```

-   TÆ°Æ¡ng tá»± vá»›i m
-   Ká»³ vá»ng: ChÃªnh lá»‡ch nhá»

##### **3. XÃ¡c suáº¥t dá»± Ä‘oÃ¡n**

```python
print(f"  - ChÃªnh lá»‡ch:           {abs(predicted_score_manual - predicted_proba_sklearn):.6f}")
```

-   So sÃ¡nh output cuá»‘i cÃ¹ng
-   **Quan trá»ng nháº¥t:** Káº¿t quáº£ dá»± Ä‘oÃ¡n cÃ³ Ä‘Ãºng khÃ´ng?
-   Ká»³ vá»ng: ChÃªnh lá»‡ch ráº¥t nhá» (< 0.01)

##### **4. Káº¿t luáº­n cuá»‘i cÃ¹ng**

```python
result_manual = "Äáº¬U" if predicted_score_manual >= 0.5 else "Rá»šT"
result_sklearn = "Äáº¬U" if predicted_class_sklearn == 1 else "Rá»šT"
```

-   Chuyá»ƒn sá»‘ thÃ nh text Ä‘á»ƒ dá»… Ä‘á»c
-   So sÃ¡nh string Ä‘á»ƒ kiá»ƒm tra consistency

```python
if result_manual == result_sklearn:
    print(f"  - Káº¿t quáº£: GIá»NG NHAU âœ“")
else:
    print(f"  - Káº¿t quáº£: KHÃC NHAU âœ—")
```

-   **Náº¿u giá»‘ng:** âœ“ Implementation Ä‘Ãºng!
-   **Náº¿u khÃ¡c:** âœ— CÃ³ váº¥n Ä‘á» cáº§n check

---

### 6ï¸âƒ£ Pháº§n Káº¿t Luáº­n Tá»•ng Quan

```python
print("\n" + "="*60)
print("Káº¾T LUáº¬N")
print("="*60)
print("CÃ³ thá»ƒ tháº¥y sá»± khÃ¡c biá»‡t giá»¯a hai mÃ´ hÃ¬nh do:")
print("  1. Sá»‘ láº§n láº·p khÃ¡c nhau (10 vs thuáº­t toÃ¡n tá»‘i Æ°u cá»§a sklearn)")
print("  2. PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u khÃ¡c nhau (Gradient Descent vs LBFGS)")
print("  3. Äiá»u kiá»‡n dá»«ng vÃ  khá»Ÿi táº¡o tham sá»‘ khÃ¡c nhau")
print("="*60 + "\n")
```

**Giáº£i thÃ­ch:**

#### **LÃ½ do cÃ³ sá»± khÃ¡c biá»‡t**

##### **1. Sá»‘ láº§n láº·p khÃ¡c nhau**

-   **Manual:** ÄÃºng 10 iterations, khÃ´ng thÃªm khÃ´ng bá»›t
-   **Sklearn:** CÃ³ thá»ƒ há»™i tá»¥ sá»›m hÆ¡n náº¿u Ä‘áº¡t tolerance
    -   Máº·c Ä‘á»‹nh `tol=1e-4`
    -   Dá»«ng khi gradient < tolerance
    -   CÃ³ thá»ƒ dá»«ng sau 5-8 iterations

##### **2. PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u khÃ¡c nhau**

**Manual - Gradient Descent:**

-   CÃ´ng thá»©c: $w_{new} = w_{old} - \alpha \nabla J$
-   **Gradient báº­c 1** (first-order derivative)
-   ÄÆ¡n giáº£n, dá»… hiá»ƒu
-   Tá»‘c Ä‘á»™ há»™i tá»¥: **tuyáº¿n tÃ­nh** (linear)

**Sklearn - LBFGS:**

-   **Quasi-Newton method**
-   Sá»­ dá»¥ng **gradient báº­c 2** (approximated Hessian)
-   Phá»©c táº¡p hÆ¡n nhÆ°ng **hiá»‡u quáº£ hÆ¡n**
-   Tá»‘c Ä‘á»™ há»™i tá»¥: **siÃªu tuyáº¿n tÃ­nh** (superlinear)

**VÃ­ dá»¥:**

-   GD: 10 steps â†’ Cost giáº£m 60%
-   LBFGS: 10 steps â†’ Cost giáº£m 95%

##### **3. Äiá»u kiá»‡n dá»«ng vÃ  khá»Ÿi táº¡o**

**Khá»Ÿi táº¡o:**

-   Manual: m=1.0, b=-1.0 (do mÃ¬nh chá»n)
-   Sklearn: w=0, b=0 (máº·c Ä‘á»‹nh) hoáº·c random

**Äiá»u kiá»‡n dá»«ng:**

-   Manual: Cháº¡y Ä‘Ãºng 10 iterations, khÃ´ng check convergence
-   Sklearn: Dá»«ng khi `||gradient|| < tol` hoáº·c `max_iter`

**Learning rate:**

-   Manual: Cá»‘ Ä‘á»‹nh (1.0)
-   Sklearn: Adaptive (LBFGS tá»± Ä‘iá»u chá»‰nh)

---

### 7ï¸âƒ£ Visualization

#### **7.1. Táº¡o Figure vá»›i 2 Subplots**

```python
# ========== VISUALIZATION ==========

# Táº¡o figure vá»›i 2 subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
```

**Giáº£i thÃ­ch:**

-   Táº¡o 2 biá»ƒu Ä‘á»“ cáº¡nh nhau
-   KÃ­ch thÆ°á»›c lá»›n (14Ã—5) Ä‘á»ƒ rÃµ rÃ ng

---

#### **7.2. Subplot 1: So SÃ¡nh Decision Boundary**

```python
# Subplot 1: So sÃ¡nh decision boundary cá»§a 2 mÃ´ hÃ¬nh
x_plot = np.linspace(0, 4.5, 100)
y_manual = [get_prediction(m, b, x_i) for x_i in x_plot]
y_sklearn = [model.predict_proba([[x_i]])[0][1] for x_i in x_plot]
```

**Giáº£i thÃ­ch:**

##### **Táº¡o dáº£i x**

```python
x_plot = np.linspace(0, 4.5, 100)
```

-   100 Ä‘iá»ƒm tá»« 0 Ä‘áº¿n 4.5
-   Äá»§ má»‹n Ä‘á»ƒ váº½ Ä‘Æ°á»ng cong mÆ°á»£t

##### **TÃ­nh y cho manual model**

```python
y_manual = [get_prediction(m, b, x_i) for x_i in x_plot]
```

-   List comprehension: duyá»‡t 100 Ä‘iá»ƒm
-   Gá»i hÃ m `get_prediction` tá»« module tá»± xÃ¢y dá»±ng
-   Káº¿t quáº£: 100 giÃ¡ trá»‹ xÃ¡c suáº¥t

##### **TÃ­nh y cho sklearn**

```python
y_sklearn = [model.predict_proba([[x_i]])[0][1] for x_i in x_plot]
```

-   `[[x_i]]`: Reshape thÃ nh 2D array
-   `predict_proba(...)`: Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t
-   `[0][1]`: Láº¥y xÃ¡c suáº¥t class 1

**LÆ°u Ã½:** CÃ¡ch tÃ­nh hÆ¡i "cá»“ng ká»nh" vá»›i list comprehension, cÃ³ thá»ƒ optimize:

```python
# CÃ¡ch tá»‘t hÆ¡n:
X_plot = x_plot.reshape(-1, 1)
y_sklearn = model.predict_proba(X_plot)[:, 1]
```

---

##### **Váº½ dá»¯ liá»‡u gá»‘c**

```python
# Váº½ dá»¯ liá»‡u gá»‘c
x_data = [row[0] for row in DATASET]
y_data = [row[1] for row in DATASET]
ax1.scatter(x_data, y_data, c=['red' if y==0 else 'green' for y in y_data],
            s=100, alpha=0.6, edgecolors='black', linewidth=1.5,
            label='Dá»¯ liá»‡u thá»±c táº¿', zorder=3)
```

**Giáº£i thÃ­ch:**

-   **`c=[...]`:** MÃ u theo nhÃ£n

    -   `'red' if y==0`: Rá»›t â†’ Ä‘á»
    -   `'green'`: Äáº­u â†’ xanh
    -   List comprehension táº¡o list mÃ u: `['red', 'red', ..., 'green', 'green']`

-   **`s=100`:** KÃ­ch thÆ°á»›c Ä‘iá»ƒm = 100

-   **`alpha=0.6`:** Äá»™ trong suá»‘t 60% (hÆ¡i má»)

-   **`edgecolors='black'`:** Viá»n Ä‘en cho rÃµ

-   **`linewidth=1.5`:** Äá»™ dÃ y viá»n

-   **`zorder=3`:** Layer cao (váº½ trÃªn cÃ¹ng)
    -   Äáº£m báº£o Ä‘iá»ƒm khÃ´ng bá»‹ Ä‘Æ°á»ng che

---

##### **Váº½ Ä‘Æ°á»ng sigmoid**

```python
# Váº½ Ä‘Æ°á»ng sigmoid
ax1.plot(x_plot, y_manual, 'b-', linewidth=2, label='MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng')
ax1.plot(x_plot, y_sklearn, 'r--', linewidth=2, label='Sklearn')
```

**Giáº£i thÃ­ch:**

-   **Manual:**

    -   `'b-'`: MÃ u xanh (blue), Ä‘Æ°á»ng liá»n (solid)
    -   `linewidth=2`: Äá»™ dÃ y 2

-   **Sklearn:**
    -   `'r--'`: MÃ u Ä‘á» (red), Ä‘Æ°á»ng gáº¡ch (dashed)
    -   Dá»… phÃ¢n biá»‡t vá»›i manual

**Ká»³ vá»ng:** 2 Ä‘Æ°á»ng ráº¥t gáº§n nhau, gáº§n nhÆ° trÃ¹ng

---

##### **Váº½ ngÆ°á»¡ng 0.5**

```python
# Váº½ ngÆ°á»¡ng 0.5
ax1.axhline(y=0.5, color='gray', linestyle=':', linewidth=1, label='NgÆ°á»¡ng 0.5')
```

**Giáº£i thÃ­ch:**

-   `axhline`: ÄÆ°á»ng ngang
-   `y=0.5`: Táº¡i y = 0.5
-   `linestyle=':'`: ÄÆ°á»ng cháº¥m (dotted)
-   **Ã nghÄ©a:** Decision boundary threshold

---

##### **Váº½ Ä‘iá»ƒm dá»± Ä‘oÃ¡n 2.8h**

```python
# Váº½ Ä‘iá»ƒm dá»± Ä‘oÃ¡n cho 2.8 giá»
ax1.scatter([hours_input], [predicted_score_manual], c='blue', s=200,
            marker='*', edgecolors='black', linewidth=1.5,
            label=f'Dá»± Ä‘oÃ¡n {hours_input}h (Manual)', zorder=4)
ax1.scatter([hours_input], [predicted_proba_sklearn], c='red', s=200,
            marker='*', edgecolors='black', linewidth=1.5,
            label=f'Dá»± Ä‘oÃ¡n {hours_input}h (Sklearn)', zorder=4)
```

**Giáº£i thÃ­ch:**

-   **Marker `'*'`:** HÃ¬nh ngÃ´i sao (ná»•i báº­t)
-   **`s=200`:** KÃ­ch thÆ°á»›c lá»›n
-   **`zorder=4`:** Layer cao nháº¥t (váº½ trÃªn cÃ¹ng)
-   **2 Ä‘iá»ƒm:**
    -   Manual: Xanh
    -   Sklearn: Äá»
-   **Ká»³ vá»ng:** 2 Ä‘iá»ƒm ráº¥t gáº§n nhau (gáº§n nhÆ° trÃ¹ng)

---

##### **Trang trÃ­ subplot 1**

```python
ax1.set_xlabel('Sá»‘ giá» há»c', fontsize=11, fontweight='bold')
ax1.set_ylabel('XÃ¡c suáº¥t Ä‘áº­u', fontsize=11, fontweight='bold')
ax1.set_title('So sÃ¡nh Decision Boundary\nMÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng vs Sklearn', fontsize=12, fontweight='bold')
ax1.legend(loc='upper left', fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_ylim(-0.1, 1.1)
```

**Giáº£i thÃ­ch:**

-   **Title:** 2 dÃ²ng vá»›i `\n`
-   **Legend:** GÃ³c trÃªn trÃ¡i
-   **Grid:** Äá»™ trong suá»‘t 0.3
-   **ylim:** -0.1 Ä‘áº¿n 1.1 (hÆ¡i rá»™ng hÆ¡n 0-1)

---

#### **7.3. Subplot 2: So SÃ¡nh Tham Sá»‘**

```python
# Subplot 2: So sÃ¡nh cÃ¡c tham sá»‘
categories = ['Há»‡ sá»‘ gÃ³c\n(m/coef)', 'Há»‡ sá»‘ cháº·n\n(b/intercept)', f'XÃ¡c suáº¥t Ä‘áº­u\n({hours_input}h)']
manual_values = [m, b, predicted_score_manual]
sklearn_values = [model.coef_[0][0], model.intercept_[0], predicted_proba_sklearn]

x_pos = np.arange(len(categories))
width = 0.35

bars1 = ax2.bar(x_pos - width/2, manual_values, width, label='MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng', color='skyblue', edgecolor='black', linewidth=1.5)
bars2 = ax2.bar(x_pos + width/2, sklearn_values, width, label='Sklearn', color='salmon', edgecolor='black', linewidth=1.5)
```

**Giáº£i thÃ­ch:**

##### **Chuáº©n bá»‹ dá»¯ liá»‡u**

**Categories:**

```python
categories = ['Há»‡ sá»‘ gÃ³c\n(m/coef)', 'Há»‡ sá»‘ cháº·n\n(b/intercept)', f'XÃ¡c suáº¥t Ä‘áº­u\n({hours_input}h)']
```

-   3 nhÃ³m so sÃ¡nh
-   `\n`: Xuá»‘ng dÃ²ng trong label (Ä‘áº¹p hÆ¡n)

**Values:**

```python
manual_values = [m, b, predicted_score_manual]
sklearn_values = [model.coef_[0][0], model.intercept_[0], predicted_proba_sklearn]
```

-   2 list tÆ°Æ¡ng á»©ng

##### **Táº¡o vá»‹ trÃ­ cá»™t**

```python
x_pos = np.arange(len(categories))  # [0, 1, 2]
width = 0.35
```

-   `x_pos`: Vá»‹ trÃ­ trung tÃ¢m má»—i nhÃ³m
-   `width`: Äá»™ rá»™ng má»—i cá»™t = 0.35

##### **Váº½ grouped bar chart**

```python
bars1 = ax2.bar(x_pos - width/2, manual_values, width, ...)
bars2 = ax2.bar(x_pos + width/2, sklearn_values, width, ...)
```

**PhÃ¢n tÃ­ch:**

-   **`x_pos - width/2`:** Dá»‹ch sang trÃ¡i ná»­a width

    -   Vá»‹ trÃ­: [-0.175, 0.825, 1.825]

-   **`x_pos + width/2`:** Dá»‹ch sang pháº£i ná»­a width
    -   Vá»‹ trÃ­: [0.175, 1.175, 2.175]

**Káº¿t quáº£:** 2 cá»™t Ä‘á»©ng sÃ¡t nhau, táº¡o nhÃ³m

**MÃ u sáº¯c:**

-   Manual: `'skyblue'` (xanh nháº¡t)
-   Sklearn: `'salmon'` (Ä‘á» nháº¡t)
-   Viá»n Ä‘en cho rÃµ

---

##### **ThÃªm giÃ¡ trá»‹ lÃªn cá»™t**

```python
# ThÃªm giÃ¡ trá»‹ lÃªn cÃ¡c cá»™t
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontsize=9, fontweight='bold')
```

**Giáº£i thÃ­ch:**

-   **Duyá»‡t 2 nhÃ³m cá»™t:** bars1, bars2
-   **Duyá»‡t tá»«ng cá»™t:** bar in bars
-   **Láº¥y chiá»u cao:** `bar.get_height()` = giÃ¡ trá»‹
-   **Váº½ text:**
    -   **Vá»‹ trÃ­ X:** Trung tÃ¢m cá»™t
        -   `bar.get_x()`: Tá»a Ä‘á»™ trÃ¡i cá»™t
        -   `+ bar.get_width()/2.`: Cá»™ng ná»­a width â†’ trung tÃ¢m
    -   **Vá»‹ trÃ­ Y:** `height` (Ä‘á»‰nh cá»™t)
    -   **Text:** GiÃ¡ trá»‹ vá»›i 3 chá»¯ sá»‘ tháº­p phÃ¢n
    -   **`ha='center'`:** Horizontal alignment = center
    -   **`va='bottom'`:** Vertical alignment = bottom (Ä‘áº·t dÆ°á»›i chá»¯)

**Káº¿t quáº£:** Má»—i cá»™t cÃ³ sá»‘ á»Ÿ trÃªn Ä‘á»‰nh

---

##### **Trang trÃ­ subplot 2**

```python
ax2.set_ylabel('GiÃ¡ trá»‹', fontsize=11, fontweight='bold')
ax2.set_title('So sÃ¡nh Tham sá»‘ vÃ  Káº¿t quáº£ Dá»± Ä‘oÃ¡n', fontsize=12, fontweight='bold')
ax2.set_xticks(x_pos)
ax2.set_xticklabels(categories, fontsize=10)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3, axis='y')
ax2.axhline(y=0, color='black', linewidth=0.8)
```

**Giáº£i thÃ­ch:**

-   **`set_xticks(x_pos)`:** Äáº·t vá»‹ trÃ­ tick = [0, 1, 2]
-   **`set_xticklabels(categories)`:** Gáº¯n nhÃ£n cho tick
-   **`grid(axis='y')`:** Chá»‰ váº½ grid ngang (khÃ´ng dá»c)
-   **`axhline(y=0)`:** Váº½ trá»¥c x táº¡i y=0 (baseline)

---

#### **7.4. LÆ°u vÃ  Hiá»ƒn Thá»‹**

```python
plt.tight_layout()
plt.savefig('results/ex2b_comparison_chart.png', dpi=300, bbox_inches='tight')
plt.show()
```

**Giáº£i thÃ­ch:**

-   LÆ°u vÃ o thÆ° má»¥c `results/`
-   TÃªn file rÃµ rÃ ng: `ex2b_comparison_chart.png`
-   DPI cao (300) cho cháº¥t lÆ°á»£ng tá»‘t

---

## ğŸ“Š Output vÃ  Káº¿t Quáº£ (Dá»± Kiáº¿n)

### ğŸ–¥ï¸ Console Output

```
============================================================
BÃ€I 2 - QUESTION B: SO SÃNH MÃ” HÃŒNH Tá»° XÃ‚Y Dá»°NG Vá»šI SKLEARN
============================================================

------------------------------------------------------------
PHáº¦N A: Káº¾T QUáº¢ MÃ” HÃŒNH Tá»° XÃ‚Y Dá»°NG
------------------------------------------------------------
Tham sá»‘ há»c Ä‘Æ°á»£c:
  - Há»‡ sá»‘ gÃ³c (m): 2.345678
  - Há»‡ sá»‘ cháº·n (b): -4.567890

Dá»± Ä‘oÃ¡n cho sinh viÃªn há»c 2.8 giá»:
  - XÃ¡c suáº¥t Ä‘áº­u: 0.785432 (78.54%)
  - Káº¿t luáº­n: Äáº¬U

------------------------------------------------------------
PHáº¦N B: Káº¾T QUáº¢ MÃ” HÃŒNH SKLEARN
------------------------------------------------------------
Tham sá»‘ há»c Ä‘Æ°á»£c:
  - Há»‡ sá»‘ gÃ³c (coef): 2.398765
  - Há»‡ sá»‘ cháº·n (intercept): -4.612345

Dá»± Ä‘oÃ¡n cho sinh viÃªn há»c 2.8 giá»:
  - XÃ¡c suáº¥t Ä‘áº­u: 0.791234 (79.12%)
  - Káº¿t luáº­n: Äáº¬U

Há»‡ sá»‘ gÃ³c (m/coef):
  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: 2.345678
  - Sklearn:              2.398765
  - ChÃªnh lá»‡ch:           0.053087

Há»‡ sá»‘ cháº·n (b/intercept):
  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: -4.567890
  - Sklearn:              -4.612345
  - ChÃªnh lá»‡ch:           0.044455

XÃ¡c suáº¥t Ä‘áº­u cho 2.8 giá» há»c:
  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: 0.785432 (78.54%)
  - Sklearn:              0.791234 (79.12%)
  - ChÃªnh lá»‡ch:           0.005802

Káº¿t luáº­n dá»± Ä‘oÃ¡n:
  - MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng: Äáº¬U
  - Sklearn:             Äáº¬U
  - Káº¿t quáº£: GIá»NG NHAU âœ“

============================================================
Káº¾T LUáº¬N
============================================================
CÃ³ thá»ƒ tháº¥y sá»± khÃ¡c biá»‡t giá»¯a hai mÃ´ hÃ¬nh do:
  1. Sá»‘ láº§n láº·p khÃ¡c nhau (10 vs thuáº­t toÃ¡n tá»‘i Æ°u cá»§a sklearn)
  2. PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u khÃ¡c nhau (Gradient Descent vs LBFGS)
  3. Äiá»u kiá»‡n dá»«ng vÃ  khá»Ÿi táº¡o tham sá»‘ khÃ¡c nhau
============================================================
```

---

### ğŸ“ˆ PhÃ¢n TÃ­ch Káº¿t Quáº£

#### **1. Tham Sá»‘ (m/coef, b/intercept)**

**ChÃªnh lá»‡ch nhá» (~5-6%):**

-   Manual: m=2.35, b=-4.57
-   Sklearn: m=2.40, b=-4.61
-   **NguyÃªn nhÃ¢n:**
    -   LBFGS há»™i tá»¥ tá»‘t hÆ¡n GD
    -   Sklearn cÃ³ thá»ƒ Ä‘Ã£ há»™i tá»¥ sá»›m
    -   Khá»Ÿi táº¡o khÃ¡c nhau

**Ã nghÄ©a:**

-   **CÃ¹ng hÆ°á»›ng:** Cáº£ 2 Ä‘á»u há»c Ä‘Æ°á»£c xu hÆ°á»›ng tÄƒng (m > 0)
-   **CÃ¹ng dá»‹ch:** Cáº£ 2 Ä‘á»u cÃ³ b Ã¢m (dá»‹ch sang pháº£i)
-   **Consistency:** Implementation cÆ¡ báº£n Ä‘Ãºng!

---

#### **2. XÃ¡c Suáº¥t Dá»± ÄoÃ¡n**

**ChÃªnh lá»‡ch ráº¥t nhá» (<1%):**

-   Manual: 78.54%
-   Sklearn: 79.12%
-   **ChÃªnh lá»‡ch:** 0.58%

**Ã nghÄ©a:**

-   **Gáº§n nhÆ° giá»‘ng nhau:** Cáº£ 2 mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tÆ°Æ¡ng tá»±
-   **CÃ¹ng káº¿t luáº­n:** Äá»u dá»± Ä‘oÃ¡n Äáº¬U
-   **Tin cáº­y:** Implementation manual lÃ  Ä‘Ã¡ng tin cáº­y

---

#### **3. Káº¿t Luáº­n Cuá»‘i CÃ¹ng**

**GIá»NG NHAU âœ“**

-   Cáº£ 2 Ä‘á»u káº¿t luáº­n Äáº¬U
-   **Quan trá»ng nháº¥t:** Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng giá»‘ng nhau
-   **ThÃ nh cÃ´ng:** MÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng hoáº¡t Ä‘á»™ng Ä‘Ãºng!

---

#### **4. Biá»ƒu Äá»“ 1: Decision Boundary**

**Quan sÃ¡t:**

-   **2 Ä‘Æ°á»ng sigmoid:** Gáº§n nhÆ° trÃ¹ng nhau
-   **Äiá»ƒm dá»¯ liá»‡u:** PhÃ¢n bá»‘ rÃµ rÃ ng (Ä‘á» trÃ¡i, xanh pháº£i)
-   **2 ngÃ´i sao (2.8h):** Ráº¥t gáº§n nhau (~79%)
-   **NgÆ°á»¡ng 0.5:** 2 Ä‘Æ°á»ng Ä‘á»u vÆ°á»£t qua táº¡i ~2.0-2.2 giá»

**Káº¿t luáº­n:**

-   MÃ´ hÃ¬nh manual **hoáº¡t Ä‘á»™ng tá»‘t**
-   Decision boundary **há»£p lÃ½**

---

#### **5. Biá»ƒu Äá»“ 2: So SÃ¡nh Tham Sá»‘**

**Quan sÃ¡t:**

**NhÃ³m 1 - Há»‡ sá»‘ gÃ³c:**

-   Manual: ~2.35 (xanh)
-   Sklearn: ~2.40 (Ä‘á»)
-   **Cao gáº§n báº±ng nhau**

**NhÃ³m 2 - Há»‡ sá»‘ cháº·n:**

-   Manual: ~-4.57 (xanh, Ã¢m)
-   Sklearn: ~-4.61 (Ä‘á», Ã¢m)
-   **Cáº£ 2 Ä‘á»u Ã¢m, gáº§n nhau**

**NhÃ³m 3 - XÃ¡c suáº¥t Ä‘áº­u:**

-   Manual: ~0.785 (xanh)
-   Sklearn: ~0.791 (Ä‘á»)
-   **Gáº§n nhÆ° báº±ng nhau**

**Káº¿t luáº­n:**

-   **Visual confirmation:** Máº¯t thÆ°á»ng tháº¥y 2 cá»™t gáº§n nhau
-   **ChÃªnh lá»‡ch nhá»:** Acceptable difference

---