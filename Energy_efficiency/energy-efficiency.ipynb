{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02f3046",
   "metadata": {},
   "source": [
    "# Energy Efficiency Prediction using Linear Regression\n",
    "\n",
    "This notebook implements Linear Regression for predicting building energy efficiency (heating load Y1 and cooling load Y2).\n",
    "\n",
    "## Dataset Features:\n",
    "- **X1**: Relative Compactness\n",
    "- **X2**: Surface Area (m¬≤)\n",
    "- **X3**: Wall Area (m¬≤)\n",
    "- **X4**: Roof Area (m¬≤)\n",
    "- **X5**: Overall Height (m)\n",
    "- **X6**: Orientation (2-5)\n",
    "- **X7**: Glazing Area (0-0.4)\n",
    "- **X8**: Glazing Area Distribution (0-5)\n",
    "\n",
    "## Targets:\n",
    "- **Y1**: Heating Load (kWh/m¬≤)\n",
    "- **Y2**: Cooling Load (kWh/m¬≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0fdd3",
   "metadata": {},
   "source": [
    "## üìö Th∆∞ vi·ªán v√† C·∫•u h√¨nh\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt cho ph√¢n t√≠ch Machine Learning\n",
    "\n",
    "**Th∆∞ vi·ªán ch√≠nh:**\n",
    "- `numpy`, `pandas`: X·ª≠ l√Ω d·ªØ li·ªáu v√† t√≠nh to√°n\n",
    "- `matplotlib`, `seaborn`: Tr·ª±c quan h√≥a d·ªØ li·ªáu\n",
    "- `sklearn`: Thu·∫≠t to√°n Machine Learning, preprocessing, metrics\n",
    "- `scipy.stats`: Ki·ªÉm ƒë·ªãnh th·ªëng k√™ (Q-Q plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf6c67",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a32c1dd",
   "metadata": {},
   "source": [
    "**C√¥ng vi·ªác:** \n",
    "- Load d·ªØ li·ªáu t·ª´ file CSV\n",
    "- Lo·∫°i b·ªè c·ªôt r·ªóng\n",
    "- Ph√¢n t√≠ch c·∫•u tr√∫c: shape, data types, missing values, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (768, 11)\n",
      "\n",
      "======================================================================\n",
      "First few rows:\n",
      "   Unnamed: 0    X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
      "0           1  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
      "1           2  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
      "2           3  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
      "3           4  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
      "4           5  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28\n",
      "5           6  0.90  563.5  318.5  122.50  7.0   3  0.0   0  21.46  25.38\n",
      "6           7  0.90  563.5  318.5  122.50  7.0   4  0.0   0  20.71  25.16\n",
      "7           8  0.90  563.5  318.5  122.50  7.0   5  0.0   0  19.68  29.60\n",
      "8           9  0.86  588.0  294.0  147.00  7.0   2  0.0   0  19.50  27.30\n",
      "9          10  0.86  588.0  294.0  147.00  7.0   3  0.0   0  19.95  21.97\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  768 non-null    int64  \n",
      " 1   X1          768 non-null    float64\n",
      " 2   X2          768 non-null    float64\n",
      " 3   X3          768 non-null    float64\n",
      " 4   X4          768 non-null    float64\n",
      " 5   X5          768 non-null    float64\n",
      " 6   X6          768 non-null    int64  \n",
      " 7   X7          768 non-null    float64\n",
      " 8   X8          768 non-null    int64  \n",
      " 9   Y1          768 non-null    float64\n",
      " 10  Y2          768 non-null    float64\n",
      "dtypes: float64(8), int64(3)\n",
      "memory usage: 66.1 KB\n",
      "None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Statistical Summary:\n",
      "       Unnamed: 0          X1          X2          X3          X4         X5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.00000   \n",
      "mean   384.500000    0.764167  671.708333  318.500000  176.604167    5.25000   \n",
      "std    221.846794    0.105777   88.086116   43.626481   45.165950    1.75114   \n",
      "min      1.000000    0.620000  514.500000  245.000000  110.250000    3.50000   \n",
      "25%    192.750000    0.682500  606.375000  294.000000  140.875000    3.50000   \n",
      "50%    384.500000    0.750000  673.750000  318.500000  183.750000    5.25000   \n",
      "75%    576.250000    0.830000  741.125000  343.000000  220.500000    7.00000   \n",
      "max    768.000000    0.980000  808.500000  416.500000  220.500000    7.00000   \n",
      "\n",
      "               X6          X7         X8          Y1          Y2  \n",
      "count  768.000000  768.000000  768.00000  768.000000  768.000000  \n",
      "mean     3.500000    0.234375    2.81250   22.307201   24.587760  \n",
      "std      1.118763    0.133221    1.55096   10.090196    9.513306  \n",
      "min      2.000000    0.000000    0.00000    6.010000   10.900000  \n",
      "25%      2.750000    0.100000    1.75000   12.992500   15.620000  \n",
      "50%      3.500000    0.250000    3.00000   18.950000   22.080000  \n",
      "75%      4.250000    0.400000    4.00000   31.667500   33.132500  \n",
      "max      5.000000    0.400000    5.00000   43.100000   48.030000  \n",
      "\n",
      "======================================================================\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0    0\n",
      "X1            0\n",
      "X2            0\n",
      "X3            0\n",
      "X4            0\n",
      "X5            0\n",
      "X6            0\n",
      "X7            0\n",
      "X8            0\n",
      "Y1            0\n",
      "Y2            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"ENB2012_data.csv\", index_col=0)\n",
    "\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"First few rows:\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d69922",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c725a20",
   "metadata": {},
   "source": [
    "**B∆∞·ªõc chu·∫©n b·ªã d·ªØ li·ªáu:**\n",
    "\n",
    "1. **T√°ch features v√† targets:** \n",
    "   - Features (X): 8 bi·∫øn ƒë·ªôc l·∫≠p (X1-X8)\n",
    "   - Targets: Y1 (Heating Load), Y2 (Cooling Load)\n",
    "\n",
    "2. **Train-Test Split (80-20):**\n",
    "   - Training set: 80% d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "   - Testing set: 20% d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh\n",
    "\n",
    "3. **Feature Scaling (Standardization):**\n",
    "   \n",
    "   $$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "   \n",
    "   Trong ƒë√≥:\n",
    "   - $x$: gi√° tr·ªã g·ªëc\n",
    "   - $\\mu$: trung b√¨nh (mean)\n",
    "   - $\\sigma$: ƒë·ªô l·ªách chu·∫©n (standard deviation)\n",
    "   - $z$: gi√° tr·ªã chu·∫©n h√≥a\n",
    "   \n",
    "   **L·ª£i √≠ch:** ƒê∆∞a t·∫•t c·∫£ features v·ªÅ c√πng scale, gi√∫p model h·ªôi t·ª• nhanh h∆°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and targets\n",
    "X = df.iloc[:, :-2].values  # X1 to X8 features\n",
    "y1 = df['Y1'].values  # Heating Load\n",
    "y2 = df['Y2'].values  # Cooling Load\n",
    "\n",
    "# Feature names for later use\n",
    "feature_names = ['X1_Compactness', 'X2_SurfaceArea', 'X3_WallArea', \n",
    "                 'X4_RoofArea', 'X5_Height', 'X6_Orientation', \n",
    "                 'X7_GlazingArea', 'X8_GlazingDist']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Y1 (Heating Load) shape:\", y1.shape)\n",
    "print(\"Y2 (Cooling Load) shape:\", y2.shape)\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "# Using stratified approach would be ideal but for regression we use random split\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(\n",
    "    X, y1, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train2, X_test2, y2_train, y2_test = train_test_split(\n",
    "    X, y2, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])\n",
    "\n",
    "# Feature Scaling (Standardization)\n",
    "# Standardization is crucial for Linear Regression with multiple features\n",
    "# Formula: z = (x - Œº) / œÉ\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# For Y2 we use the same split (same X features)\n",
    "X_train2_scaled = X_train_scaled\n",
    "X_test2_scaled = X_test_scaled\n",
    "\n",
    "print(\"\\n‚úì Data preparation completed!\")\n",
    "print(f\"Feature means after scaling (should be ~0): {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Feature stds after scaling (should be ~1): {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "print(\"=\"*70)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create correlation matrix\n",
    "df_features = df.copy()\n",
    "correlation_matrix = df_features.corr()\n",
    "\n",
    "# Correlation with targets\n",
    "print(\"\\nCorrelation with Y1 (Heating Load):\")\n",
    "y1_corr = correlation_matrix['Y1'].drop('Y1').sort_values(ascending=False)\n",
    "print(y1_corr)\n",
    "\n",
    "print(\"\\nCorrelation with Y2 (Cooling Load):\")\n",
    "y2_corr = correlation_matrix['Y2'].drop('Y2').sort_values(ascending=False)\n",
    "print(y2_corr)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Full correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=axes[0], cbar_kws={'shrink': 0.8})\n",
    "axes[0].set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Correlation with targets only\n",
    "target_corr = pd.DataFrame({\n",
    "    'Y1': correlation_matrix['Y1'].drop(['Y1', 'Y2']),\n",
    "    'Y2': correlation_matrix['Y2'].drop(['Y1', 'Y2'])\n",
    "})\n",
    "sns.heatmap(target_corr, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            center=0, ax=axes[1], cbar_kws={'shrink': 0.8})\n",
    "axes[1].set_title('Features Correlation with Targets', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Correlation analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc97d45",
   "metadata": {},
   "source": [
    "### 2.1 Feature Correlation Analysis\n",
    "\n",
    "Ph√¢n t√≠ch correlation gi√∫p hi·ªÉu m·ªëi quan h·ªá gi·ªØa features v√† targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2ab72",
   "metadata": {},
   "source": [
    "## 3. Linear Regression Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a57c1d",
   "metadata": {},
   "source": [
    "**Thu·∫≠t to√°n Linear Regression:**\n",
    "\n",
    "M√¥ h√¨nh d·ª± ƒëo√°n d·ª±a tr√™n ph∆∞∆°ng tr√¨nh tuy·∫øn t√≠nh:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$$\n",
    "\n",
    "Ho·∫∑c d·∫°ng vector:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\mathbf{X}\\boldsymbol{\\beta}$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $\\hat{y}$: gi√° tr·ªã d·ª± ƒëo√°n\n",
    "- $\\beta_0$: intercept (h·∫±ng s·ªë)\n",
    "- $\\beta_1, \\beta_2, ..., \\beta_n$: coefficients (h·ªá s·ªë)\n",
    "- $x_1, x_2, ..., x_n$: features (bi·∫øn ƒë·ªôc l·∫≠p)\n",
    "\n",
    "**Ph∆∞∆°ng ph√°p t·ªëi ∆∞u:** Ordinary Least Squares (OLS)\n",
    "\n",
    "$$\\min_{\\boldsymbol{\\beta}} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Nghi·ªám gi·∫£i t√≠ch:**\n",
    "\n",
    "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression for Y1 (Heating Load)\n",
    "print(\"Training Linear Regression Model for Y1 (Heating Load)...\")\n",
    "model_y1 = LinearRegression()\n",
    "model_y1.fit(X_train_scaled, y1_train)\n",
    "\n",
    "# Predictions for Y1\n",
    "y1_pred_train = model_y1.predict(X_train_scaled)\n",
    "y1_pred_test = model_y1.predict(X_test_scaled)\n",
    "\n",
    "print(\"‚úì Y1 Model trained successfully!\")\n",
    "print(f\"  Intercept: {model_y1.intercept_:.4f}\")\n",
    "print(f\"  Number of features: {len(model_y1.coef_)}\")\n",
    "print(f\"  Coefficient range: [{model_y1.coef_.min():.4f}, {model_y1.coef_.max():.4f}]\")\n",
    "\n",
    "# Train Linear Regression for Y2 (Cooling Load)\n",
    "print(\"\\nTraining Linear Regression Model for Y2 (Cooling Load)...\")\n",
    "model_y2 = LinearRegression()\n",
    "model_y2.fit(X_train2_scaled, y2_train)\n",
    "\n",
    "# Predictions for Y2\n",
    "y2_pred_train = model_y2.predict(X_train2_scaled)\n",
    "y2_pred_test = model_y2.predict(X_test2_scaled)\n",
    "\n",
    "print(\"‚úì Y2 Model trained successfully!\")\n",
    "print(f\"  Intercept: {model_y2.intercept_:.4f}\")\n",
    "print(f\"  Number of features: {len(model_y2.coef_)}\")\n",
    "print(f\"  Coefficient range: [{model_y2.coef_.min():.4f}, {model_y2.coef_.max():.4f}]\")\n",
    "\n",
    "# Quick performance check on training set (to detect overfitting)\n",
    "train_r2_y1 = r2_score(y1_train, y1_pred_train)\n",
    "train_r2_y2 = r2_score(y2_train, y2_pred_train)\n",
    "print(f\"\\nTraining R¬≤ scores:\")\n",
    "print(f\"  Y1: {train_r2_y1:.4f}\")\n",
    "print(f\"  Y2: {train_r2_y2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fae5d",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5f61d",
   "metadata": {},
   "source": [
    "**C√°c ch·ªâ s·ªë ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh:**\n",
    "\n",
    "1. **R¬≤ (Coefficient of Determination):**\n",
    "   \n",
    "   $$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
    "   \n",
    "   - Gi√° tr·ªã: 0 ƒë·∫øn 1 (c√†ng cao c√†ng t·ªët)\n",
    "   - √ù nghƒ©a: % ph∆∞∆°ng sai c·ªßa y ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi m√¥ h√¨nh\n",
    "   - $R^2 = 1$: d·ª± ƒëo√°n ho√†n h·∫£o\n",
    "   - $R^2 = 0$: m√¥ h√¨nh kh√¥ng t·ªët h∆°n vi·ªác d·ª± ƒëo√°n theo trung b√¨nh\n",
    "\n",
    "2. **RMSE (Root Mean Squared Error):**\n",
    "   \n",
    "   $$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
    "   \n",
    "   - Gi√° tr·ªã: ‚â• 0 (c√†ng th·∫•p c√†ng t·ªët)\n",
    "   - √ù nghƒ©a: ƒê·ªô l·ªách trung b√¨nh gi·ªØa gi√° tr·ªã th·ª±c v√† d·ª± ƒëo√°n\n",
    "   - Nh·∫°y v·ªõi outliers (do b√¨nh ph∆∞∆°ng sai s·ªë)\n",
    "\n",
    "3. **MAE (Mean Absolute Error):**\n",
    "   \n",
    "   $$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n",
    "   \n",
    "   - Gi√° tr·ªã: ‚â• 0 (c√†ng th·∫•p c√†ng t·ªët)\n",
    "   - √ù nghƒ©a: Sai s·ªë tuy·ªát ƒë·ªëi trung b√¨nh\n",
    "   - √çt nh·∫°y v·ªõi outliers h∆°n RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display metrics\n",
    "def evaluate_model(y_true, y_pred, dataset_name, target_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{target_name} - {dataset_name} Set Metrics:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"R¬≤ (Coefficient of Determination): {r2:.6f}\")\n",
    "    print(f\"RMSE (Root Mean Squared Error):    {rmse:.6f}\")\n",
    "    print(f\"MAE (Mean Absolute Error):          {mae:.6f}\")\n",
    "    \n",
    "    return {'R2': r2, 'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Evaluate Y1 Model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Y1 MODEL EVALUATION (HEATING LOAD)\")\n",
    "print(\"=\"*70)\n",
    "y1_train_metrics = evaluate_model(y1_train, y1_pred_train, \"Training\", \"Y1\")\n",
    "y1_test_metrics = evaluate_model(y1_test, y1_pred_test, \"Testing\", \"Y1\")\n",
    "\n",
    "# Evaluate Y2 Model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Y2 MODEL EVALUATION (COOLING LOAD)\")\n",
    "print(\"=\"*70)\n",
    "y2_train_metrics = evaluate_model(y2_train, y2_pred_train, \"Training\", \"Y2\")\n",
    "y2_test_metrics = evaluate_model(y2_test, y2_pred_test, \"Testing\", \"Y2\")\n",
    "\n",
    "# Create comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY COMPARISON TABLE\")\n",
    "print(\"=\"*70)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Y1_Train': [y1_train_metrics['R2'], y1_train_metrics['RMSE'], y1_train_metrics['MAE']],\n",
    "    'Y1_Test': [y1_test_metrics['R2'], y1_test_metrics['RMSE'], y1_test_metrics['MAE']],\n",
    "    'Y2_Train': [y2_train_metrics['R2'], y2_train_metrics['RMSE'], y2_train_metrics['MAE']],\n",
    "    'Y2_Test': [y2_test_metrics['R2'], y2_test_metrics['RMSE'], y2_test_metrics['MAE']]\n",
    "}, index=['R¬≤', 'RMSE', 'MAE'])\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting/Underfitting Analysis\n",
    "print(\"=\"*70)\n",
    "print(\"OVERFITTING/UNDERFITTING ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate train-test gaps\n",
    "for target_name, train_pred, test_pred, y_train_true, y_test_true in [\n",
    "    ('Y1', y1_pred_train, y1_pred_test, y1_train, y1_test),\n",
    "    ('Y2', y2_pred_train, y2_pred_test, y2_train, y2_test)\n",
    "]:\n",
    "    train_r2 = r2_score(y_train_true, train_pred)\n",
    "    test_r2 = r2_score(y_test_true, test_pred)\n",
    "    r2_gap = train_r2 - test_r2\n",
    "    \n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_true, train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_true, test_pred))\n",
    "    rmse_gap = test_rmse - train_rmse\n",
    "    \n",
    "    print(f\"\\n{target_name} Analysis:\")\n",
    "    print(f\"  Train R¬≤: {train_r2:.6f}\")\n",
    "    print(f\"  Test R¬≤:  {test_r2:.6f}\")\n",
    "    print(f\"  R¬≤ Gap:   {r2_gap:.6f} {'‚ö†Ô∏è (possible overfitting)' if r2_gap > 0.05 else '‚úì (good)'}\")\n",
    "    \n",
    "    print(f\"  Train RMSE: {train_rmse:.6f}\")\n",
    "    print(f\"  Test RMSE:  {test_rmse:.6f}\")\n",
    "    print(f\"  RMSE Gap:   {rmse_gap:.6f} {'‚ö†Ô∏è (possible overfitting)' if rmse_gap > 1.0 else '‚úì (good)'}\")\n",
    "    \n",
    "    # Diagnosis\n",
    "    if train_r2 > 0.95 and test_r2 > 0.95 and r2_gap < 0.02:\n",
    "        status = \"‚úì EXCELLENT FIT - No overfitting detected\"\n",
    "    elif train_r2 > 0.90 and test_r2 > 0.85 and r2_gap < 0.05:\n",
    "        status = \"‚úì GOOD FIT - Model generalizes well\"\n",
    "    elif r2_gap > 0.1:\n",
    "        status = \"‚ö†Ô∏è WARNING - Possible overfitting\"\n",
    "    elif train_r2 < 0.7 and test_r2 < 0.7:\n",
    "        status = \"‚ö†Ô∏è WARNING - Underfitting (model too simple)\"\n",
    "    else:\n",
    "        status = \"~ ACCEPTABLE FIT\"\n",
    "    \n",
    "    print(f\"  Status: {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01efe85",
   "metadata": {},
   "source": [
    "### 4.1 Overfitting/Underfitting Analysis\n",
    "\n",
    "**Ki·ªÉm tra hi·ªán t∆∞·ª£ng:**\n",
    "- **Overfitting:** Training score >> Test score (model h·ªçc thu·ªôc l√≤ng data)\n",
    "- **Underfitting:** C·∫£ Training v√† Test scores ƒë·ªÅu th·∫•p (model qu√° ƒë∆°n gi·∫£n)\n",
    "- **Good fit:** Training score ‚âà Test score v√† c·∫£ hai ƒë·ªÅu cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3699f5c",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832df18",
   "metadata": {},
   "source": [
    "**K-Fold Cross-Validation:**\n",
    "\n",
    "K·ªπ thu·∫≠t ƒë√°nh gi√° m√¥ h√¨nh ƒë√°ng tin c·∫≠y h∆°n train-test split ƒë∆°n thu·∫ßn.\n",
    "\n",
    "**Quy tr√¨nh:**\n",
    "1. Chia dataset th√†nh K folds (K=10)\n",
    "2. L·∫∑p K l·∫ßn:\n",
    "   - Fold th·ª© i l√†m validation set\n",
    "   - K-1 folds c√≤n l·∫°i l√†m training set\n",
    "   - Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "3. T√≠nh trung b√¨nh c·ªßa K k·∫øt qu·∫£\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:**\n",
    "- S·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu cho c·∫£ training v√† validation\n",
    "- Gi·∫£m variance trong ƒë√°nh gi√°\n",
    "- Ph√°t hi·ªán overfitting/underfitting t·ªët h∆°n\n",
    "\n",
    "**C√¥ng th·ª©c Cross-Validation Score:**\n",
    "\n",
    "$$CV_{score} = \\frac{1}{K}\\sum_{i=1}^{K} Score_i$$\n",
    "\n",
    "$$CV_{std} = \\sqrt{\\frac{1}{K}\\sum_{i=1}^{K}(Score_i - CV_{score})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 10-Fold Cross-Validation\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Performing 10-Fold Cross-Validation...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Scale entire dataset for CV\n",
    "X_scaled_full = scaler_X.fit_transform(X)\n",
    "\n",
    "# Cross-validation for Y1\n",
    "cv_r2_y1 = cross_val_score(model_y1, X_scaled_full, y1, cv=kfold, scoring='r2')\n",
    "cv_mse_y1 = -cross_val_score(model_y1, X_scaled_full, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "cv_rmse_y1 = np.sqrt(cv_mse_y1)\n",
    "cv_mae_y1 = -cross_val_score(model_y1, X_scaled_full, y1, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"\\nY1 (Heating Load) Cross-Validation Results:\")\n",
    "print(f\"  R¬≤ scores: {cv_r2_y1}\")\n",
    "print(f\"  Mean R¬≤: {cv_r2_y1.mean():.6f} (+/- {cv_r2_y1.std():.6f})\")\n",
    "print(f\"  RMSE scores: {cv_rmse_y1}\")\n",
    "print(f\"  Mean RMSE: {cv_rmse_y1.mean():.6f} (+/- {cv_rmse_y1.std():.6f})\")\n",
    "print(f\"  MAE scores: {cv_mae_y1}\")\n",
    "print(f\"  Mean MAE: {cv_mae_y1.mean():.6f} (+/- {cv_mae_y1.std():.6f})\")\n",
    "\n",
    "# Cross-validation for Y2\n",
    "cv_r2_y2 = cross_val_score(model_y2, X_scaled_full, y2, cv=kfold, scoring='r2')\n",
    "cv_mse_y2 = -cross_val_score(model_y2, X_scaled_full, y2, cv=kfold, scoring='neg_mean_squared_error')\n",
    "cv_rmse_y2 = np.sqrt(cv_mse_y2)\n",
    "cv_mae_y2 = -cross_val_score(model_y2, X_scaled_full, y2, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"\\nY2 (Cooling Load) Cross-Validation Results:\")\n",
    "print(f\"  R¬≤ scores: {cv_r2_y2}\")\n",
    "print(f\"  Mean R¬≤: {cv_r2_y2.mean():.6f} (+/- {cv_r2_y2.std():.6f})\")\n",
    "print(f\"  RMSE scores: {cv_rmse_y2}\")\n",
    "print(f\"  Mean RMSE: {cv_rmse_y2.mean():.6f} (+/- {cv_rmse_y2.std():.6f})\")\n",
    "print(f\"  MAE scores: {cv_mae_y2}\")\n",
    "print(f\"  Mean MAE: {cv_mae_y2.mean():.6f} (+/- {cv_mae_y2.std():.6f})\")\n",
    "\n",
    "# Store CV results for plotting\n",
    "cv_results = {\n",
    "    'Y1_R2': cv_r2_y1,\n",
    "    'Y1_RMSE': cv_rmse_y1,\n",
    "    'Y1_MAE': cv_mae_y1,\n",
    "    'Y2_R2': cv_r2_y2,\n",
    "    'Y2_RMSE': cv_rmse_y2,\n",
    "    'Y2_MAE': cv_mae_y2\n",
    "}\n",
    "\n",
    "print(\"\\n‚úì Cross-validation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a5273",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "### 6.1 Parity Plots (Predicted vs True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b2fdb",
   "metadata": {},
   "source": [
    "**Parity Plot (Predicted vs True Values):**\n",
    "\n",
    "- **Tr·ª•c X:** Gi√° tr·ªã th·ª±c t·∫ø (ground truth)\n",
    "- **Tr·ª•c Y:** Gi√° tr·ªã d·ª± ƒëo√°n (predictions)\n",
    "- **ƒê∆∞·ªùng ƒë·ªè:** $y = x$ (d·ª± ƒëo√°n ho√†n h·∫£o)\n",
    "\n",
    "**C√°ch ƒë·ªçc:**\n",
    "- ƒêi·ªÉm c√†ng g·∫ßn ƒë∆∞·ªùng ƒë·ªè ‚Üí d·ª± ƒëo√°n c√†ng ch√≠nh x√°c\n",
    "- Scatter t·∫≠p trung ‚Üí model ·ªïn ƒë·ªãnh\n",
    "- Scatter ph√¢n t√°n ‚Üí model kh√¥ng ·ªïn ƒë·ªãnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity Plots using loop for cleaner code\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Data for both targets\n",
    "targets_data = [\n",
    "    {'y_test': y1_test, 'y_pred': y1_pred_test, 'metrics': y1_test_metrics, \n",
    "     'name': 'Y1 (Heating Load)', 'color': 'tab:blue'},\n",
    "    {'y_test': y2_test, 'y_pred': y2_pred_test, 'metrics': y2_test_metrics, \n",
    "     'name': 'Y2 (Cooling Load)', 'color': 'tab:green'}\n",
    "]\n",
    "\n",
    "for idx, data in enumerate(targets_data):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(data['y_test'], data['y_pred'], alpha=0.6, s=50, \n",
    "              color=data['color'], edgecolors='k', linewidth=0.5, label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val, max_val = data['y_test'].min(), data['y_test'].max()\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel(f'True {data[\"name\"]}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(f'Predicted {data[\"name\"]}', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{data[\"name\"]} Parity Plot\\n' + \n",
    "                f'R¬≤ = {data[\"metrics\"][\"R2\"]:.4f}, RMSE = {data[\"metrics\"][\"RMSE\"]:.4f}',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Parity plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ba2f6",
   "metadata": {},
   "source": [
    "### 6.2 Residual Plots (Residuals vs Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea3318",
   "metadata": {},
   "source": [
    "**Residual Plot:**\n",
    "\n",
    "Residual (sai s·ªë): $e_i = y_i - \\hat{y}_i$\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** Ki·ªÉm tra gi·∫£ ƒë·ªãnh c·ªßa Linear Regression\n",
    "\n",
    "**M·∫´u l√Ω t∆∞·ªüng:**\n",
    "- Residuals ph√¢n b·ªë ng·∫´u nhi√™n xung quanh 0\n",
    "- Kh√¥ng c√≥ pattern (h√¨nh d·∫°ng) r√µ r√†ng\n",
    "- Variance ƒë·ªìng ƒë·ªÅu (homoscedasticity)\n",
    "\n",
    "**N·∫øu c√≥ pattern:**\n",
    "- H√¨nh cong ‚Üí c·∫ßn th√™m polynomial features\n",
    "- H√¨nh ph·ªÖu ‚Üí heteroscedasticity (vi ph·∫°m gi·∫£ ƒë·ªãnh)\n",
    "- Outliers ‚Üí c·∫ßn xem x√©t lo·∫°i b·ªè ho·∫∑c x·ª≠ l√Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f57f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals_data = [\n",
    "    {'pred': y1_pred_test, 'residuals': y1_test - y1_pred_test, \n",
    "     'name': 'Y1 (Heating Load)', 'color': 'tab:blue'},\n",
    "    {'pred': y2_pred_test, 'residuals': y2_test - y2_pred_test, \n",
    "     'name': 'Y2 (Cooling Load)', 'color': 'tab:green'}\n",
    "]\n",
    "\n",
    "# Residual plots using loop\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, data in enumerate(residuals_data):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(data['pred'], data['residuals'], alpha=0.6, s=50,\n",
    "              color=data['color'], edgecolors='k', linewidth=0.5)\n",
    "    \n",
    "    # Zero residual line\n",
    "    ax.axhline(y=0, color='r', linestyle='--', lw=2, label='Zero Residual')\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel(f'Predicted {data[\"name\"]}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Residuals', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{data[\"name\"]} Residual Plot\\n(Residuals vs Predicted)',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Residual plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f6893",
   "metadata": {},
   "source": [
    "### 6.3 Residual Distribution Analysis (Histogram + Q-Q Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ddadd",
   "metadata": {},
   "source": [
    "**Ki·ªÉm tra ph√¢n ph·ªëi Residuals:**\n",
    "\n",
    "**1. Histogram:**\n",
    "   - Ki·ªÉm tra xem residuals c√≥ ph√¢n ph·ªëi chu·∫©n (normal distribution) kh√¥ng\n",
    "   - L√Ω t∆∞·ªüng: H√¨nh chu√¥ng ƒë·ªëi x·ª©ng quanh 0\n",
    "\n",
    "**2. Q-Q Plot (Quantile-Quantile Plot):**\n",
    "   - So s√°nh quantiles c·ªßa residuals v·ªõi ph√¢n ph·ªëi chu·∫©n l√Ω thuy·∫øt\n",
    "   - L√Ω t∆∞·ªüng: C√°c ƒëi·ªÉm n·∫±m tr√™n ƒë∆∞·ªùng th·∫≥ng\n",
    "   \n",
    "**Gi·∫£ ƒë·ªãnh Linear Regression:**\n",
    "$$\\epsilon_i \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Residuals n√™n tu√¢n theo ph√¢n ph·ªëi chu·∫©n v·ªõi mean = 0 v√† variance = $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Distribution Analysis using loop\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Store residuals for both targets\n",
    "y1_residuals = y1_test - y1_pred_test\n",
    "y2_residuals = y2_test - y2_pred_test\n",
    "\n",
    "residual_dist_data = [\n",
    "    {'residuals': y1_residuals, 'name': 'Y1', 'color': 'skyblue', 'row': 0},\n",
    "    {'residuals': y2_residuals, 'name': 'Y2', 'color': 'lightgreen', 'row': 1}\n",
    "]\n",
    "\n",
    "for data in residual_dist_data:\n",
    "    row = data['row']\n",
    "    \n",
    "    # Histogram\n",
    "    axes[row, 0].hist(data['residuals'], bins=30, edgecolor='black', \n",
    "                     alpha=0.7, color=data['color'])\n",
    "    axes[row, 0].axvline(x=0, color='r', linestyle='--', lw=2, label='Zero')\n",
    "    axes[row, 0].set_xlabel('Residuals', fontsize=12, fontweight='bold')\n",
    "    axes[row, 0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    axes[row, 0].set_title(f'{data[\"name\"]} Residual Histogram', \n",
    "                          fontsize=14, fontweight='bold')\n",
    "    axes[row, 0].legend()\n",
    "    axes[row, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q Plot\n",
    "    stats.probplot(data['residuals'], dist=\"norm\", plot=axes[row, 1])\n",
    "    axes[row, 1].set_title(f'{data[\"name\"]} Q-Q Plot', fontsize=14, fontweight='bold')\n",
    "    axes[row, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Residual distribution analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fad96f",
   "metadata": {},
   "source": [
    "### 6.4 Cross-Validation Boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a9acc",
   "metadata": {},
   "source": [
    "**Boxplot c·ªßa Cross-Validation Scores:**\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh qua c√°c folds\n",
    "\n",
    "**C√°ch ƒë·ªçc:**\n",
    "- **Median (ƒë∆∞·ªùng gi·ªØa h·ªôp):** Gi√° tr·ªã trung v·ªã\n",
    "- **Box (h·ªôp):** Interquartile range (IQR) - 50% d·ªØ li·ªáu ·ªü gi·ªØa\n",
    "- **Whiskers (r√¢u):** Min v√† Max trong kho·∫£ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c\n",
    "- **Outliers (ƒëi·ªÉm):** Gi√° tr·ªã b·∫•t th∆∞·ªùng\n",
    "\n",
    "**ƒê√°nh gi√°:**\n",
    "- Box h·∫πp ‚Üí Model ·ªïn ƒë·ªãnh\n",
    "- Box r·ªông ‚Üí Model kh√¥ng ·ªïn ƒë·ªãnh gi·ªØa c√°c folds\n",
    "- Nhi·ªÅu outliers ‚Üí C·∫ßn xem x√©t l·∫°i data ho·∫∑c model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation Boxplots using loop for cleaner code\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 16))\n",
    "\n",
    "# Metrics configuration\n",
    "metrics_config = [\n",
    "    {'key': 'R2', 'ylabel': 'R¬≤', 'row': 0, 'colors': ['skyblue', 'lightgreen']},\n",
    "    {'key': 'RMSE', 'ylabel': 'RMSE', 'row': 1, 'colors': ['skyblue', 'lightgreen']},\n",
    "    {'key': 'MAE', 'ylabel': 'MAE', 'row': 2, 'colors': ['skyblue', 'lightgreen']}\n",
    "]\n",
    "\n",
    "for config in metrics_config:\n",
    "    row = config['row']\n",
    "    \n",
    "    # Individual boxplots for Y1 and Y2\n",
    "    for col, target in enumerate(['Y1', 'Y2']):\n",
    "        data_key = f'{target}_{config[\"key\"]}'\n",
    "        bp = axes[row, col].boxplot([cv_results[data_key]], labels=[target], patch_artist=True)\n",
    "        bp['boxes'][0].set_facecolor(config['colors'][col])\n",
    "        \n",
    "        axes[row, col].set_ylabel(config['ylabel'], fontsize=12, fontweight='bold')\n",
    "        axes[row, col].set_title(f'{target}: {config[\"ylabel\"]} Cross-Validation',\n",
    "                                fontsize=13, fontweight='bold')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics\n",
    "        data = cv_results[data_key]\n",
    "        axes[row, col].text(0.98, 0.98, \n",
    "                           f'Mean: {data.mean():.4f}\\nStd: {data.std():.4f}',\n",
    "                           transform=axes[row, col].transAxes,\n",
    "                           verticalalignment='top', horizontalalignment='right',\n",
    "                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                           fontsize=9)\n",
    "    \n",
    "    # Comparison boxplot\n",
    "    y1_data = cv_results[f'Y1_{config[\"key\"]}']\n",
    "    y2_data = cv_results[f'Y2_{config[\"key\"]}']\n",
    "    bp = axes[row, 2].boxplot([y1_data, y2_data], labels=['Y1', 'Y2'], patch_artist=True)\n",
    "    \n",
    "    for patch, color in zip(bp['boxes'], config['colors']):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[row, 2].set_ylabel(config['ylabel'], fontsize=12, fontweight='bold')\n",
    "    axes[row, 2].set_title(f'{config[\"ylabel\"]} Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[row, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì All cross-validation boxplots generated (R¬≤, RMSE, MAE)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd88fb",
   "metadata": {},
   "source": [
    "### 6.5 Coefficient Plot (Feature Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facabec4",
   "metadata": {},
   "source": [
    "**Coefficient Plot (Feature Importance):**\n",
    "\n",
    "**√ù nghƒ©a c·ªßa coefficients ($\\beta_i$):**\n",
    "- ƒê·ªô l·ªõn (magnitude): M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa feature\n",
    "- D·∫•u (+/-):\n",
    "  - D∆∞∆°ng (+): Feature tƒÉng ‚Üí Target tƒÉng\n",
    "  - √Çm (-): Feature tƒÉng ‚Üí Target gi·∫£m\n",
    "\n",
    "**Gi·∫£i th√≠ch:**\n",
    "$$\\frac{\\partial y}{\\partial x_i} = \\beta_i$$\n",
    "\n",
    "Khi $x_i$ tƒÉng 1 ƒë∆°n v·ªã (sau standardization), $y$ thay ƒë·ªïi $\\beta_i$ ƒë∆°n v·ªã.\n",
    "\n",
    "**L∆∞u √Ω:** Features ƒë√£ ƒë∆∞·ª£c standardized, n√™n c√≥ th·ªÉ so s√°nh tr·ª±c ti·∫øp magnitude c·ªßa coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82998101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient plots using loop for cleaner code\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Models configuration\n",
    "models_config = [\n",
    "    {'model': model_y1, 'name': 'Y1 (Heating Load)', 'color': 'skyblue', 'idx': 0},\n",
    "    {'model': model_y2, 'name': 'Y2 (Cooling Load)', 'color': 'lightgreen', 'idx': 1}\n",
    "]\n",
    "\n",
    "for config in models_config:\n",
    "    ax = axes[config['idx']]\n",
    "    coef = config['model'].coef_\n",
    "    \n",
    "    # Horizontal bar chart\n",
    "    ax.barh(feature_names, coef, color=config['color'], edgecolor='black')\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Features', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{config[\"name\"]} - Feature Coefficients\\n' +\n",
    "                f'Intercept: {config[\"model\"].intercept_:.4f}',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add coefficient values on bars\n",
    "    for i, (name, value) in enumerate(zip(feature_names, coef)):\n",
    "        ax.text(value, i, f' {value:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Coefficient plots generated!\")\n",
    "\n",
    "# Print coefficient summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COEFFICIENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Y1_Coefficient': model_y1.coef_,\n",
    "    'Y2_Coefficient': model_y2.coef_,\n",
    "    'Y1_Abs': np.abs(model_y1.coef_),\n",
    "    'Y2_Abs': np.abs(model_y2.coef_)\n",
    "})\n",
    "coef_df = coef_df.sort_values('Y1_Abs', ascending=False)\n",
    "print(coef_df[['Feature', 'Y1_Coefficient', 'Y2_Coefficient']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92539515",
   "metadata": {},
   "source": [
    "## 7. Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c11dd",
   "metadata": {},
   "source": [
    "**T·ªïng k·∫øt to√†n b·ªô ph√¢n t√≠ch:**\n",
    "\n",
    "Ph·∫ßn n√†y t·ªïng h·ª£p:\n",
    "1. Th√¥ng tin dataset\n",
    "2. Hi·ªáu su·∫•t m√¥ h√¨nh (Test set v√† Cross-validation)\n",
    "3. So s√°nh gi·ªØa Y1 v√† Y2\n",
    "4. Feature quan tr·ªçng nh·∫•t\n",
    "5. ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t·ªïng th·ªÉ\n",
    "6. C√°c bi·ªÉu ƒë·ªì ƒë√£ t·∫°o\n",
    "\n",
    "**Ti√™u ch√≠ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng:**\n",
    "- **EXCELLENT:** R¬≤ > 0.9 cho c·∫£ 2 targets\n",
    "- **VERY GOOD:** R¬≤ > 0.8 cho c·∫£ 2 targets  \n",
    "- **GOOD:** R¬≤ > 0.7 cho c·∫£ 2 targets\n",
    "- **MODERATE:** R¬≤ < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary Report\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"ENERGY EFFICIENCY PREDICTION - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä DATASET INFORMATION:\")\n",
    "print(f\"  ‚Ä¢ Total samples: {len(df)}\")\n",
    "print(f\"  ‚Ä¢ Training samples: {len(X_train)}\")\n",
    "print(f\"  ‚Ä¢ Testing samples: {len(X_test)}\")\n",
    "print(f\"  ‚Ä¢ Number of features: {X.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Target variables: Y1 (Heating Load), Y2 (Cooling Load)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ Y1 (HEATING LOAD) MODEL PERFORMANCE:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Test Set Metrics:\")\n",
    "print(f\"    ‚Ä¢ R¬≤ Score:  {y1_test_metrics['R2']:.6f}\")\n",
    "print(f\"    ‚Ä¢ RMSE:      {y1_test_metrics['RMSE']:.6f}\")\n",
    "print(f\"    ‚Ä¢ MAE:       {y1_test_metrics['MAE']:.6f}\")\n",
    "print(f\"\\n  Cross-Validation (10-Fold):\")\n",
    "print(f\"    ‚Ä¢ Mean R¬≤:   {cv_r2_y1.mean():.6f} ¬± {cv_r2_y1.std():.6f}\")\n",
    "print(f\"    ‚Ä¢ Mean RMSE: {cv_rmse_y1.mean():.6f} ¬± {cv_rmse_y1.std():.6f}\")\n",
    "print(f\"    ‚Ä¢ Mean MAE:  {cv_mae_y1.mean():.6f} ¬± {cv_mae_y1.std():.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ Y2 (COOLING LOAD) MODEL PERFORMANCE:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  Test Set Metrics:\")\n",
    "print(f\"    ‚Ä¢ R¬≤ Score:  {y2_test_metrics['R2']:.6f}\")\n",
    "print(f\"    ‚Ä¢ RMSE:      {y2_test_metrics['RMSE']:.6f}\")\n",
    "print(f\"    ‚Ä¢ MAE:       {y2_test_metrics['MAE']:.6f}\")\n",
    "print(f\"\\n  Cross-Validation (10-Fold):\")\n",
    "print(f\"    ‚Ä¢ Mean R¬≤:   {cv_r2_y2.mean():.6f} ¬± {cv_r2_y2.std():.6f}\")\n",
    "print(f\"    ‚Ä¢ Mean RMSE: {cv_rmse_y2.mean():.6f} ¬± {cv_rmse_y2.std():.6f}\")\n",
    "print(f\"    ‚Ä¢ Mean MAE:  {cv_mae_y2.mean():.6f} ¬± {cv_mae_y2.std():.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç KEY INSIGHTS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine best performing target\n",
    "if y1_test_metrics['R2'] > y2_test_metrics['R2']:\n",
    "    better_target = \"Y1 (Heating Load)\"\n",
    "    better_r2 = y1_test_metrics['R2']\n",
    "else:\n",
    "    better_target = \"Y2 (Cooling Load)\"\n",
    "    better_r2 = y2_test_metrics['R2']\n",
    "\n",
    "print(f\"  ‚Ä¢ Best performing target: {better_target} with R¬≤ = {better_r2:.6f}\")\n",
    "\n",
    "# Feature importance\n",
    "abs_coef_y1 = np.abs(model_y1.coef_)\n",
    "abs_coef_y2 = np.abs(model_y2.coef_)\n",
    "most_important_y1 = feature_names[np.argmax(abs_coef_y1)]\n",
    "most_important_y2 = feature_names[np.argmax(abs_coef_y2)]\n",
    "\n",
    "print(f\"  ‚Ä¢ Most important feature for Y1: {most_important_y1}\")\n",
    "print(f\"  ‚Ä¢ Most important feature for Y2: {most_important_y2}\")\n",
    "\n",
    "# Model quality assessment\n",
    "if y1_test_metrics['R2'] > 0.9 and y2_test_metrics['R2'] > 0.9:\n",
    "    quality = \"EXCELLENT\"\n",
    "elif y1_test_metrics['R2'] > 0.8 and y2_test_metrics['R2'] > 0.8:\n",
    "    quality = \"VERY GOOD\"\n",
    "elif y1_test_metrics['R2'] > 0.7 and y2_test_metrics['R2'] > 0.7:\n",
    "    quality = \"GOOD\"\n",
    "else:\n",
    "    quality = \"MODERATE\"\n",
    "\n",
    "print(f\"  ‚Ä¢ Overall model quality: {quality}\")\n",
    "print(f\"  ‚Ä¢ Both models show {'consistent' if abs(y1_test_metrics['R2'] - y2_test_metrics['R2']) < 0.05 else 'varying'} performance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ CONCLUSIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"  ‚Ä¢ Linear Regression successfully predicts building energy efficiency\")\n",
    "print(\"  ‚Ä¢ High R¬≤ scores indicate strong linear relationships\")\n",
    "print(\"  ‚Ä¢ Low RMSE and MAE values confirm prediction accuracy\")\n",
    "print(\"  ‚Ä¢ Cross-validation results show model stability and generalization\")\n",
    "print(\"  ‚Ä¢ Feature coefficients reveal important building characteristics\")\n",
    "print(\"  ‚Ä¢ Model is ready for practical energy efficiency assessment\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù GENERATED VISUALIZATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"  ‚úì Parity plots (Predicted vs True) for Y1 and Y2\")\n",
    "print(\"  ‚úì Residual plots (Residuals vs Predicted) for Y1 and Y2\")\n",
    "print(\"  ‚úì Residual histograms for Y1 and Y2\")\n",
    "print(\"  ‚úì Q-Q plots for residual normality check\")\n",
    "print(\"  ‚úì Cross-validation boxplots for R¬≤, RMSE, and MAE\")\n",
    "print(\"  ‚úì Coefficient plots showing feature importance\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ LINEAR REGRESSION ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
